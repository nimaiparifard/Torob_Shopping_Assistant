#!/usr/bin/env python3
"""
Comprehensive test suite for the router system
Tests all components: semantic routing, hard signals, intent parsing, etc.
"""

import asyncio
import sys
import time
from pathlib import Path
from typing import Dict, List, Any
import numpy as np

# Add project root to path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from router import (
    get_router_config_from_env,
    validate_config,
    MainRouter,
    RouterState,
    AgentType,
    SessionManager,
    EmbeddingService,
    HardSignalDetector,
    IntentParser,
    SemanticRouter,
    AgentExemplars
)


class RouterTestSuite:
    """Comprehensive test suite for router components"""
    
    def __init__(self):
        self.config = None
        self.router = None
        self.results = {}
        
    async def setup(self):
        """Setup test environment"""
        print("ğŸ”§ Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ù…Ø­ÛŒØ· ØªØ³Øª...")
        
        # Validate config
        if not validate_config():
            raise RuntimeError("Configuration validation failed!")
        
        # Load config
        self.config = get_router_config_from_env()
        print(f"âœ… Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯")
        
        # Initialize main router
        self.router = MainRouter(self.config)
        await self.router.initialize()
        print(f"âœ… Router Ø§ØµÙ„ÛŒ Ø¢Ù…Ø§Ø¯Ù‡ Ø´Ø¯")
        
        self.results = {
            'embedding_tests': [],
            'hard_signal_tests': [],
            'intent_parsing_tests': [],
            'semantic_routing_tests': [],
            'main_router_tests': [],
            'session_management_tests': [],
            'performance_tests': []
        }
    
    async def test_embedding_service(self):
        """Test embedding service functionality"""
        print("\nğŸ§ª ØªØ³Øª Embedding Service...")
        
        embedding_service = EmbeddingService(self.config)
        
        test_cases = [
            "Ø³Ù„Ø§Ù… Ú†Ø·ÙˆØ±ÛŒØ¯ØŸ",
            "Ù‚ÛŒÙ…Øª Ú¯ÙˆØ´ÛŒ Ø³Ø§Ù…Ø³ÙˆÙ†Ú¯ Ú†Ù‚Ø¯Ø±Ù‡ØŸ",
            "ÛŒÙ‡ Ù„Ù¾ ØªØ§Ù¾ Ø®ÙˆØ¨ Ù…ÛŒØ®ÙˆØ§Ù…",
            "Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¢ÛŒÙÙˆÙ† Ø¨Ø§ Ø³Ø§Ù…Ø³ÙˆÙ†Ú¯",
            "Hello, how are you?"  # English test
        ]
        
        print(f"  ğŸ“ ØªØ³Øª Ø¨Ø§ {len(test_cases)} Ù…ØªÙ† Ù…Ø®ØªÙ„Ù...")
        
        # Test single embedding
        start_time = time.time()
        for i, text in enumerate(test_cases):
            embedding = await embedding_service.get_embedding(text)
            
            test_result = {
                'text': text,
                'embedding_shape': embedding.shape,
                'embedding_norm': float(np.linalg.norm(embedding)),
                'non_zero_elements': int(np.count_nonzero(embedding))
            }
            
            self.results['embedding_tests'].append(test_result)
            print(f"    âœ… Ù…ØªÙ† {i+1}: Ø´Ú©Ù„={embedding.shape}, Ù†Ø±Ù…={test_result['embedding_norm']:.3f}")
        
        # Test batch processing
        print(f"  ğŸ“¦ ØªØ³Øª Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø³ØªÙ‡â€ŒØ§ÛŒ...")
        batch_embeddings = await embedding_service.get_embeddings_batch(test_cases)
        
        # Test similarity calculation
        print(f"  ğŸ” ØªØ³Øª Ù…Ø­Ø§Ø³Ø¨Ù‡ ØªØ´Ø§Ø¨Ù‡...")
        similarities = []
        for i in range(len(batch_embeddings)):
            for j in range(i+1, len(batch_embeddings)):
                sim = embedding_service.cosine_similarity(batch_embeddings[i], batch_embeddings[j])
                similarities.append({
                    'text1': test_cases[i][:30],
                    'text2': test_cases[j][:30],
                    'similarity': float(sim)
                })
                print(f"    ğŸ“Š ØªØ´Ø§Ø¨Ù‡: {sim:.3f} - '{test_cases[i][:20]}...' vs '{test_cases[j][:20]}...'")
        
        # Test caching
        cache_size_before = embedding_service.get_cache_size()
        await embedding_service.get_embedding(test_cases[0])  # Should hit cache
        cache_size_after = embedding_service.get_cache_size()
        
        print(f"  ğŸ’¾ ØªØ³Øª Ú©Ø´: {cache_size_before} -> {cache_size_after}")
        
        elapsed_time = time.time() - start_time
        print(f"  â±ï¸  Ø²Ù…Ø§Ù† Ú©Ù„: {elapsed_time:.2f} Ø«Ø§Ù†ÛŒÙ‡")
        
        return True
    
    async def test_hard_signal_detection(self):
        """Test hard signal detection"""
        print("\nğŸ¯ ØªØ³Øª Hard Signal Detection...")
        
        detector = HardSignalDetector()
        
        test_cases = [
            # Product codes
            ("Ù„Ø·ÙØ§ Ú©Ø§Ø¨ÛŒÙ†Øª Ú†Ù‡Ø§Ø± Ú©Ø´Ùˆ Ú©Ø¯ D14 Ø±Ùˆ Ø¨Ø±Ø§Ù… Ù¾ÛŒØ¯Ø§ Ú©Ù†", AgentType.SPECIFIC_PRODUCT),
            ("Ù…Ø­ØµÙˆÙ„ Ø¨Ø§ Ø´Ù†Ø§Ø³Ù‡ SKU-12345 Ø±Ø§ Ù†Ø´Ø§Ù† Ø¨Ø¯Ù‡", AgentType.SPECIFIC_PRODUCT),
            ("Ú¯ÙˆØ´ÛŒ Ø¢ÛŒÙÙˆÙ† 15 Ù¾Ø±Ùˆ Ù…Ú©Ø³ 256 Ú¯ÛŒÚ¯", AgentType.SPECIFIC_PRODUCT),
            
            # Price inquiries
            ("Ù‚ÛŒÙ…Øª Ù¾Ø§Ø±Ú†Ù‡ Ù„ÛŒÚ©Ø±Ø§ Ø­Ù„Ù‚ÙˆÛŒ Ù†ÙˆØ±ÛŒØ³ Ú†Ù‚Ø¯Ø±Ù‡ØŸ", AgentType.PRODUCT_FEATURE),
            ("Ù‡Ø²ÛŒÙ†Ù‡ Ù„Ù¾ ØªØ§Ù¾ Ø§ÛŒØ³ÙˆØ³ Ú†Ù‚Ø¯Ø± Ø§Ø³ØªØŸ", AgentType.PRODUCT_FEATURE),
            
            # Comparisons
            ("Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¢ÛŒÙÙˆÙ† 15 Ø¨Ø§ Ø³Ø§Ù…Ø³ÙˆÙ†Ú¯ S24", AgentType.COMPARISON),
            ("Ú©Ø¯ÙˆÙ… Ø¨Ù‡ØªØ±Ù‡ØŸ Ù„Ù¾ ØªØ§Ù¾ Ø§ÛŒØ³ÙˆØ³ ÛŒØ§ Ø§Ú† Ù¾ÛŒ", AgentType.COMPARISON),
            
            # Seller info
            ("ÙØ±ÙˆØ´Ù†Ø¯Ú¯Ø§Ù† Ú¯ÙˆØ´ÛŒ Ø³Ø§Ù…Ø³ÙˆÙ†Ú¯ A54 Ú©Ø¯ÙˆÙ…Ù†ØŸ", AgentType.SELLER_INFO),
            ("Ú©Ø¯ÙˆÙ… ÙØ±ÙˆØ´Ú¯Ø§Ù‡â€ŒÙ‡Ø§ ØªØ¨Ù„Øª Ø¢ÛŒÙ¾Ø¯ Ø¯Ø§Ø±Ù†ØŸ", AgentType.SELLER_INFO),
            
            # General questions
            ("Ú†Ø·ÙˆØ± Ù…ÛŒâ€ŒØªÙˆÙ†Ù… Ø§Ø² Ø³Ø§ÛŒØª Ø®Ø±ÛŒØ¯ Ú©Ù†Ù…ØŸ", AgentType.GENERAL),
            ("Ø³Ø§Ø¹Øª Ú©Ø§Ø±ÛŒ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ú†ÛŒÙ‡ØŸ", AgentType.GENERAL),
            
            # Should not match (exploration)
            ("ÛŒÙ‡ Ù„Ù¾ ØªØ§Ù¾ Ø®ÙˆØ¨ Ø¨Ø±Ø§ÛŒ Ø¨Ø±Ù†Ø§Ù…Ù‡ Ù†ÙˆÛŒØ³ÛŒ Ù…ÛŒØ®ÙˆØ§Ù…", None),
            ("Ø¯Ù†Ø¨Ø§Ù„ ÛŒÙ‡ Ú¯ÙˆØ´ÛŒ Ù…Ù†Ø§Ø³Ø¨ Ù‡Ø³ØªÙ…", None)
        ]
        
        correct_predictions = 0
        total_tests = len(test_cases)
        
        for query, expected_agent in test_cases:
            state = RouterState(user_query=query)
            result = detector.detect(state)
            
            test_result = {
                'query': query,
                'expected': expected_agent.name if expected_agent else None,
                'detected': result.agent.name if result.agent else None,
                'confidence': result.confidence,
                'patterns': result.matched_patterns,
                'extracted_data': result.extracted_data
            }
            
            is_correct = (result.agent == expected_agent)
            if is_correct:
                correct_predictions += 1
            
            status = "âœ…" if is_correct else "âŒ"
            print(f"  {status} '{query[:50]}...'")
            print(f"      Ø§Ù†ØªØ¸Ø§Ø±: {expected_agent.name if expected_agent else 'None'}")
            print(f"      ØªØ´Ø®ÛŒØµ: {result.agent.name if result.agent else 'None'} (Ø§Ø·Ù…ÛŒÙ†Ø§Ù†: {result.confidence:.2f})")
            if result.matched_patterns:
                print(f"      Ø§Ù„Ú¯ÙˆÙ‡Ø§: {result.matched_patterns}")
            if result.extracted_data:
                print(f"      Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§: {result.extracted_data}")
            
            self.results['hard_signal_tests'].append(test_result)
        
        accuracy = correct_predictions / total_tests
        print(f"  ğŸ“Š Ø¯Ù‚Øª Hard Signals: {accuracy:.2%} ({correct_predictions}/{total_tests})")
        
        return accuracy > 0.7  # At least 70% accuracy
    
    async def test_intent_parsing(self):
        """Test intent parsing with LLM"""
        print("\nğŸ§  ØªØ³Øª Intent Parsing...")
        
        parser = IntentParser(self.config)
        
        test_cases = [
            {
                'query': 'Ù‚ÛŒÙ…Øª Ú¯ÙˆØ´ÛŒ Ø³Ø§Ù…Ø³ÙˆÙ†Ú¯ A54 Ú†Ù‚Ø¯Ø±Ù‡ØŸ',
                'expected_intent': 'feature',
                'expected_entities': ['samsung', 'a54']
            },
            {
                'query': 'ÛŒÙ‡ Ù„Ù¾ ØªØ§Ù¾ Ú¯ÛŒÙ…ÛŒÙ†Ú¯ ØªØ§ 20 Ù…ÛŒÙ„ÛŒÙˆÙ† Ù…ÛŒØ®ÙˆØ§Ù…',
                'expected_intent': 'explore',
                'expected_entities': ['laptop', 'gaming']
            },
            {
                'query': 'Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¢ÛŒÙÙˆÙ† 15 Ø¨Ø§ Ù¾ÛŒÚ©Ø³Ù„ 8',
                'expected_intent': 'compare',
                'expected_entities': ['iphone', 'pixel']
            },
            {
                'query': 'ÙØ±ÙˆØ´Ù†Ø¯Ú¯Ø§Ù† Ø¯ÛŒØ¬ÛŒ Ú©Ø§Ù„Ø§ Ú©Ø¯ÙˆÙ…Ù†ØŸ',
                'expected_intent': 'seller',
                'expected_entities': ['digikala']
            }
        ]
        
        successful_parses = 0
        
        for test_case in test_cases:
            state = RouterState(user_query=test_case['query'])
            
            try:
                intent = await parser.parse_intent(state)
                
                test_result = {
                    'query': test_case['query'],
                    'expected_intent': test_case['expected_intent'],
                    'parsed_intent': intent.intent,
                    'confidence': intent.confidence,
                    'base_ids': intent.base_ids,
                    'product_codes': intent.product_codes,
                    'brand': intent.brand,
                    'category': intent.category,
                    'price_inquiry': intent.price_inquiry
                }
                
                # Check if intent matches expectation
                intent_match = intent.intent == test_case['expected_intent']
                if intent_match:
                    successful_parses += 1
                
                status = "âœ…" if intent_match else "âŒ"
                print(f"  {status} '{test_case['query'][:50]}...'")
                print(f"      Ø§Ù†ØªØ¸Ø§Ø±: {test_case['expected_intent']}")
                print(f"      ØªØ´Ø®ÛŒØµ: {intent.intent} (Ø§Ø·Ù…ÛŒÙ†Ø§Ù†: {intent.confidence:.2f})")
                print(f"      Ø¨Ø±Ù†Ø¯: {intent.brand}, Ø¯Ø³ØªÙ‡: {intent.category}")
                print(f"      Ù‚ÛŒÙ…Øª: {intent.price_inquiry}")
                
                self.results['intent_parsing_tests'].append(test_result)
                
            except Exception as e:
                print(f"  âŒ Ø®Ø·Ø§ Ø¯Ø± ØªØ­Ù„ÛŒÙ„: {e}")
                self.results['intent_parsing_tests'].append({
                    'query': test_case['query'],
                    'error': str(e)
                })
        
        accuracy = successful_parses / len(test_cases)
        print(f"  ğŸ“Š Ø¯Ù‚Øª Intent Parsing: {accuracy:.2%} ({successful_parses}/{len(test_cases)})")
        
        return accuracy > 0.6  # At least 60% accuracy
    
    async def test_semantic_routing(self):
        """Test semantic routing with exemplars"""
        print("\nğŸ¯ ØªØ³Øª Semantic Routing...")
        
        semantic_router = SemanticRouter(self.config)
        await semantic_router.initialize()
        
        # Test exemplar similarity
        exemplars = AgentExemplars()
        
        test_cases = [
            # Should match GENERAL
            ("Ú†Ø·ÙˆØ± Ù…ÛŒâ€ŒØªÙˆÙ†Ù… Ø§Ø² Ø³Ø§ÛŒØª Ø®Ø±ÛŒØ¯ Ú©Ù†Ù…ØŸ", AgentType.GENERAL),
            ("Ø³Ø§Ø¹Øª Ú©Ø§Ø±ÛŒ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ú†ÛŒÙ‡ØŸ", AgentType.GENERAL),
            
            # Should match SPECIFIC_PRODUCT
            ("Ú¯ÙˆØ´ÛŒ Ø¢ÛŒÙÙˆÙ† 15 Ù¾Ø±Ùˆ Ù…Ú©Ø³ Ù…ÛŒØ®ÙˆØ§Ù…", AgentType.SPECIFIC_PRODUCT),
            ("Ù„Ù¾ ØªØ§Ù¾ ASUS ROG Ù…Ø¯Ù„ G15", AgentType.SPECIFIC_PRODUCT),
            
            # Should match EXPLORATION
            ("ÛŒÙ‡ Ú¯ÙˆØ´ÛŒ Ø®ÙˆØ¨ ØªØ§ 15 Ù…ÛŒÙ„ÛŒÙˆÙ† Ù…ÛŒØ®ÙˆØ§Ù…", AgentType.EXPLORATION),
            ("Ø¯Ù†Ø¨Ø§Ù„ Ù„Ù¾ ØªØ§Ù¾ Ø¨Ø±Ø§ÛŒ Ø¨Ø±Ù†Ø§Ù…Ù‡ Ù†ÙˆÛŒØ³ÛŒ Ù‡Ø³ØªÙ…", AgentType.EXPLORATION),
            
            # Should match COMPARISON
            ("ØªÙØ§ÙˆØª Ø¨ÛŒÙ† Ø¢ÛŒÙÙˆÙ† Ùˆ Ø³Ø§Ù…Ø³ÙˆÙ†Ú¯ Ú†ÛŒÙ‡ØŸ", AgentType.COMPARISON),
            ("Ú©Ø¯ÙˆÙ… Ø¨Ù‡ØªØ±Ù‡ØŸ Ù„Ù¾ ØªØ§Ù¾ Ø§ÛŒØ³ÙˆØ³ ÛŒØ§ Ù„Ù†ÙˆÙˆ", AgentType.COMPARISON)
        ]
        
        correct_matches = 0
        
        for query, expected_agent in test_cases:
            state = RouterState(user_query=query)
            decision = await semantic_router.route_by_similarity(state)
            
            # Get similar exemplars for analysis
            similar_exemplars = await semantic_router.get_similar_exemplars(
                query, decision.agent, top_k=3
            )
            
            is_correct = decision.agent == expected_agent
            if is_correct:
                correct_matches += 1
            
            test_result = {
                'query': query,
                'expected': expected_agent.name,
                'predicted': decision.agent.name,
                'confidence': decision.confidence,
                'reasoning': decision.reasoning,
                'similar_exemplars': [(text[:30], score) for text, score in similar_exemplars[:2]]
            }
            
            status = "âœ…" if is_correct else "âŒ"
            print(f"  {status} '{query[:50]}...'")
            print(f"      Ø§Ù†ØªØ¸Ø§Ø±: {expected_agent.name}")
            print(f"      ØªØ´Ø®ÛŒØµ: {decision.agent.name} (Ø§Ø·Ù…ÛŒÙ†Ø§Ù†: {decision.confidence:.2f})")
            print(f"      Ø¯Ù„ÛŒÙ„: {decision.reasoning[:50]}...")
            
            if similar_exemplars:
                print(f"      Ù†Ù…ÙˆÙ†Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø´Ø§Ø¨Ù‡:")
                for text, score in similar_exemplars[:2]:
                    print(f"        - {text[:40]}... (ØªØ´Ø§Ø¨Ù‡: {score:.3f})")
            
            self.results['semantic_routing_tests'].append(test_result)
        
        accuracy = correct_matches / len(test_cases)
        print(f"  ğŸ“Š Ø¯Ù‚Øª Semantic Routing: {accuracy:.2%} ({correct_matches}/{len(test_cases)})")
        
        # Test cache statistics
        cache_stats = semantic_router.get_cache_stats()
        print(f"  ğŸ’¾ Ø¢Ù…Ø§Ø± Ú©Ø´: {cache_stats}")
        
        return accuracy > 0.6  # At least 60% accuracy
    
    async def test_main_router_integration(self):
        """Test main router integration"""
        print("\nğŸš€ ØªØ³Øª Main Router Integration...")
        
        test_cases = [
            # Mixed scenarios
            "Ø³Ù„Ø§Ù…ØŒ Ú†Ø·ÙˆØ± Ù…ÛŒâ€ŒØªÙˆÙ†Ù… Ø®Ø±ÛŒØ¯ Ú©Ù†Ù…ØŸ",
            "Ù„Ø·ÙØ§ Ú©Ø§Ø¨ÛŒÙ†Øª Ú©Ø¯ D14 Ø±Ùˆ Ù¾ÛŒØ¯Ø§ Ú©Ù†",
            "Ù‚ÛŒÙ…Øª Ú¯ÙˆØ´ÛŒ Ø³Ø§Ù…Ø³ÙˆÙ†Ú¯ A54 Ú†Ù‚Ø¯Ø±Ù‡ØŸ",
            "ÙØ±ÙˆØ´Ù†Ø¯Ú¯Ø§Ù† Ù„Ù¾ ØªØ§Ù¾ Ø§ÛŒØ³ÙˆØ³ Ú©Ø¯ÙˆÙ…Ù†ØŸ",
            "ÛŒÙ‡ Ú¯ÙˆØ´ÛŒ Ø®ÙˆØ¨ ØªØ§ 10 Ù…ÛŒÙ„ÛŒÙˆÙ† Ù…ÛŒØ®ÙˆØ§Ù…",
            "Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¢ÛŒÙÙˆÙ† 15 Ø¨Ø§ Ø³Ø§Ù…Ø³ÙˆÙ†Ú¯ S24",
            "Ø¯Ù†Ø¨Ø§Ù„ Ù‡Ø¯ÙÙˆÙ† Ø¨ÛŒâ€ŒØ³ÛŒÙ… Ø¨Ø§ Ú©ÛŒÙÛŒØª Ø®ÙˆØ¨ Ù‡Ø³ØªÙ…"
        ]
        
        successful_routes = 0
        total_time = 0
        
        for i, query in enumerate(test_cases, 1):
            print(f"\n  ğŸ§ª ØªØ³Øª {i}: '{query[:40]}...'")
            
            start_time = time.time()
            
            try:
                state = RouterState(user_query=query, turn_count=0)
                decision = await self.router.route(state)
                
                routing_time = time.time() - start_time
                total_time += routing_time
                
                # Get detailed explanation
                explanation = await self.router.get_routing_explanation(query)
                
                test_result = {
                    'query': query,
                    'agent': decision.agent.name,
                    'confidence': decision.confidence,
                    'reasoning': decision.reasoning,
                    'routing_time': routing_time,
                    'extracted_data': decision.extracted_data,
                    'hard_signals': explanation['hard_signals'],
                    'intent_analysis': explanation['intent'],
                    'semantic_analysis': explanation['semantic']
                }
                
                print(f"    âœ… Ø¹Ø§Ù…Ù„: {decision.agent.name}")
                print(f"    ğŸ“Š Ø§Ø·Ù…ÛŒÙ†Ø§Ù†: {decision.confidence:.3f}")
                print(f"    â±ï¸  Ø²Ù…Ø§Ù†: {routing_time:.3f}s")
                print(f"    ğŸ§  Ø¯Ù„ÛŒÙ„: {decision.reasoning[:60]}...")
                
                # Show analysis breakdown
                print(f"    ğŸ” ØªØ­Ù„ÛŒÙ„:")
                print(f"      - Hard Signal: {explanation['hard_signals']['detected']} ({explanation['hard_signals']['confidence']:.2f})")
                print(f"      - Intent: {explanation['intent']['type']} ({explanation['intent']['confidence']:.2f})")
                print(f"      - Semantic: {explanation['semantic']['best_agent']} ({explanation['semantic']['confidence']:.2f})")
                
                successful_routes += 1
                self.results['main_router_tests'].append(test_result)
                
            except Exception as e:
                print(f"    âŒ Ø®Ø·Ø§: {e}")
                self.results['main_router_tests'].append({
                    'query': query,
                    'error': str(e)
                })
        
        avg_time = total_time / len(test_cases)
        success_rate = successful_routes / len(test_cases)
        
        print(f"\n  ğŸ“Š Ù†ØªØ§ÛŒØ¬ Ú©Ù„ÛŒ:")
        print(f"    - Ù†Ø±Ø® Ù…ÙˆÙÙ‚ÛŒØª: {success_rate:.2%} ({successful_routes}/{len(test_cases)})")
        print(f"    - Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø²Ù…Ø§Ù†: {avg_time:.3f}s")
        print(f"    - Ø²Ù…Ø§Ù† Ú©Ù„: {total_time:.3f}s")
        
        return success_rate > 0.8  # At least 80% success rate
    
    async def test_session_management(self):
        """Test session management"""
        print("\nğŸ‘¥ ØªØ³Øª Session Management...")
        
        session_manager = SessionManager()
        
        # Test session creation
        session = session_manager.get_or_create_session("test-user-123")
        print(f"  âœ… Ø¬Ù„Ø³Ù‡ Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯: {session.session_id}")
        
        # Simulate conversation
        conversation = [
            "Ø³Ù„Ø§Ù…ØŒ ÛŒÙ‡ Ú¯ÙˆØ´ÛŒ Ø®ÙˆØ¨ Ù…ÛŒØ®ÙˆØ§Ù…",
            "Ø¨ÙˆØ¯Ø¬Ù… Ø­Ø¯ÙˆØ¯ 15 Ù…ÛŒÙ„ÛŒÙˆÙ† ØªÙˆÙ…Ø§Ù†Ù‡",
            "ØªØ±Ø¬ÛŒØ­Ø§ Ø³Ø§Ù…Ø³ÙˆÙ†Ú¯ Ø¨Ø§Ø´Ù‡",
            "Ø¯ÙˆØ±Ø¨ÛŒÙ† Ø®ÙˆØ¨ Ø¨Ø±Ø§Ù… Ù…Ù‡Ù…Ù‡",
            "Ø¨ÛŒÙ† A54 Ùˆ A55 Ú©Ø¯ÙˆÙ… Ø¨Ù‡ØªØ±Ù‡ØŸ"
        ]
        
        for i, query in enumerate(conversation):
            state = RouterState(
                user_query=query,
                session_context=session.get_context_for_routing(),
                turn_count=session.turn_count
            )
            
            decision = await self.router.route(state)
            session.add_turn(query, decision, f"[Ù¾Ø§Ø³Ø® Ø¹Ø§Ù…Ù„ {decision.agent.name}]")
            
            print(f"  ğŸ”„ Ø¯ÙˆØ± {i+1}: {decision.agent.name} (Ø§Ø·Ù…ÛŒÙ†Ø§Ù†: {decision.confidence:.2f})")
            
            if session.should_force_conclusion:
                print(f"    âš ï¸ Ù†Ø²Ø¯ÛŒÚ© Ø¨Ù‡ Ø­Ø¯ Ù…Ø¬Ø§Ø² Ø¯ÙˆØ±Ù‡Ø§!")
        
        # Test session statistics
        stats = {
            'total_turns': session.turn_count,
            'agents_used': [agent.name for agent in session.get_previous_agents()],
            'at_limit': session.is_at_turn_limit
        }
        
        print(f"  ğŸ“Š Ø¢Ù…Ø§Ø± Ø¬Ù„Ø³Ù‡:")
        print(f"    - ØªØ¹Ø¯Ø§Ø¯ Ø¯ÙˆØ±Ù‡Ø§: {stats['total_turns']}")
        print(f"    - Ø¹Ø§Ù…Ù„â€ŒÙ‡Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø´Ø¯Ù‡: {stats['agents_used']}")
        print(f"    - Ø¯Ø± Ø­Ø¯ Ù…Ø¬Ø§Ø²: {stats['at_limit']}")
        
        # Test session manager statistics
        manager_stats = session_manager.get_session_stats()
        print(f"  ğŸ“ˆ Ø¢Ù…Ø§Ø± Ù…Ø¯ÛŒØ± Ø¬Ù„Ø³Ø§Øª:")
        print(f"    - Ú©Ù„ Ø¬Ù„Ø³Ø§Øª: {manager_stats['total_sessions']}")
        print(f"    - Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø¯ÙˆØ±Ù‡Ø§: {manager_stats['avg_turns']:.1f}")
        print(f"    - Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø¹Ø§Ù…Ù„â€ŒÙ‡Ø§: {manager_stats['agent_usage']}")
        
        self.results['session_management_tests'].append({
            'session_stats': stats,
            'manager_stats': manager_stats
        })
        
        return True
    
    async def test_performance_benchmarks(self):
        """Test performance benchmarks"""
        print("\nâš¡ ØªØ³Øª Performance Benchmarks...")
        
        # Prepare test queries
        queries = [
            "Ø³Ù„Ø§Ù… Ú†Ø·ÙˆØ±ÛŒØ¯ØŸ",
            "Ù‚ÛŒÙ…Øª Ú¯ÙˆØ´ÛŒ Ø³Ø§Ù…Ø³ÙˆÙ†Ú¯ Ú†Ù‚Ø¯Ø±Ù‡ØŸ",
            "ÛŒÙ‡ Ù„Ù¾ ØªØ§Ù¾ Ø®ÙˆØ¨ Ù…ÛŒØ®ÙˆØ§Ù…",
            "Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¢ÛŒÙÙˆÙ† Ø¨Ø§ Ø³Ø§Ù…Ø³ÙˆÙ†Ú¯",
            "ÙØ±ÙˆØ´Ù†Ø¯Ú¯Ø§Ù† Ù„Ù¾ ØªØ§Ù¾ Ú©Ø¯ÙˆÙ…Ù†ØŸ"
        ] * 10  # 50 queries total
        
        print(f"  ğŸ“Š ØªØ³Øª Ø¨Ø§ {len(queries)} Ø¯Ø±Ø®ÙˆØ§Ø³Øª...")
        
        # Test routing speed
        start_time = time.time()
        successful_routes = 0
        
        for query in queries:
            try:
                state = RouterState(user_query=query)
                decision = await self.router.route(state)
                successful_routes += 1
            except Exception as e:
                print(f"    âŒ Ø®Ø·Ø§ Ø¯Ø± '{query[:30]}...': {e}")
        
        total_time = time.time() - start_time
        avg_time_per_query = total_time / len(queries)
        queries_per_second = len(queries) / total_time
        
        performance_results = {
            'total_queries': len(queries),
            'successful_routes': successful_routes,
            'total_time': total_time,
            'avg_time_per_query': avg_time_per_query,
            'queries_per_second': queries_per_second,
            'success_rate': successful_routes / len(queries)
        }
        
        print(f"  ğŸ“ˆ Ù†ØªØ§ÛŒØ¬ Ø¹Ù…Ù„Ú©Ø±Ø¯:")
        print(f"    - Ú©Ù„ Ø¯Ø±Ø®ÙˆØ§Ø³Øªâ€ŒÙ‡Ø§: {performance_results['total_queries']}")
        print(f"    - Ù…ÙˆÙÙ‚: {performance_results['successful_routes']}")
        print(f"    - Ø²Ù…Ø§Ù† Ú©Ù„: {performance_results['total_time']:.2f}s")
        print(f"    - Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø²Ù…Ø§Ù†: {performance_results['avg_time_per_query']:.3f}s")
        print(f"    - Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø¯Ø± Ø«Ø§Ù†ÛŒÙ‡: {performance_results['queries_per_second']:.1f}")
        print(f"    - Ù†Ø±Ø® Ù…ÙˆÙÙ‚ÛŒØª: {performance_results['success_rate']:.2%}")
        
        self.results['performance_tests'].append(performance_results)
        
        return performance_results['success_rate'] > 0.9  # At least 90% success
    
    def generate_test_report(self):
        """Generate comprehensive test report"""
        print("\nğŸ“‹ Ú¯Ø²Ø§Ø±Ø´ Ú©Ø§Ù…Ù„ ØªØ³Øªâ€ŒÙ‡Ø§")
        print("=" * 60)
        
        total_tests = 0
        passed_tests = 0
        
        for test_category, results in self.results.items():
            if results:
                total_tests += 1
                # Consider test passed if we have results
                passed_tests += 1
                print(f"\nâœ… {test_category}: {len(results)} Ù†ØªÛŒØ¬Ù‡")
        
        print(f"\nğŸ“Š Ø®Ù„Ø§ØµÙ‡ Ú©Ù„ÛŒ:")
        print(f"  - Ú©Ù„ ØªØ³Øªâ€ŒÙ‡Ø§: {total_tests}")
        print(f"  - Ù…ÙˆÙÙ‚: {passed_tests}")
        print(f"  - Ù†Ø±Ø® Ù…ÙˆÙÙ‚ÛŒØª: {passed_tests/total_tests:.2%}" if total_tests > 0 else "  - Ù†Ø±Ø® Ù…ÙˆÙÙ‚ÛŒØª: 0%")
        
        return self.results
    
    async def run_all_tests(self):
        """Run all tests"""
        print("ğŸ§ª Ø´Ø±ÙˆØ¹ ØªØ³Øªâ€ŒÙ‡Ø§ÛŒ Ø¬Ø§Ù…Ø¹ Router System")
        print("=" * 60)
        
        try:
            await self.setup()
            
            # Run all test categories
            test_functions = [
                ("Embedding Service", self.test_embedding_service),
                ("Hard Signal Detection", self.test_hard_signal_detection),
                ("Intent Parsing", self.test_intent_parsing),
                ("Semantic Routing", self.test_semantic_routing),
                ("Main Router Integration", self.test_main_router_integration),
                ("Session Management", self.test_session_management),
                ("Performance Benchmarks", self.test_performance_benchmarks)
            ]
            
            passed_tests = 0
            
            for test_name, test_func in test_functions:
                try:
                    print(f"\n{'='*20} {test_name} {'='*20}")
                    result = await test_func()
                    if result:
                        passed_tests += 1
                        print(f"âœ… {test_name} - Ù…ÙˆÙÙ‚")
                    else:
                        print(f"âŒ {test_name} - Ù†Ø§Ù…ÙˆÙÙ‚")
                except Exception as e:
                    print(f"âŒ {test_name} - Ø®Ø·Ø§: {e}")
            
            # Generate final report
            self.generate_test_report()
            
            print(f"\nğŸ‰ ØªØ³Øªâ€ŒÙ‡Ø§ ØªÙ…Ø§Ù… Ø´Ø¯! {passed_tests}/{len(test_functions)} Ù…ÙˆÙÙ‚")
            
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø§ÛŒ Ú©Ù„ÛŒ Ø¯Ø± ØªØ³Øª: {e}")
            raise


async def main():
    """Main test runner"""
    test_suite = RouterTestSuite()
    await test_suite.run_all_tests()


if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\n\nâ¹ï¸ ØªØ³Øªâ€ŒÙ‡Ø§ Ù…ØªÙˆÙ‚Ù Ø´Ø¯Ù†Ø¯.")
    except Exception as e:
        print(f"\nâŒ Ø®Ø·Ø§: {e}")
        sys.exit(1)
